package parser

import (
	"fmt"
	"gomonkey/ast"
	"gomonkey/lexer"
	"gomonkey/token"
	"strconv"
)

const (
	_ int = iota
	LOWEST
	EQUALS      // =
	LESSGREATER // > ã¾ãŸã¯ <
	SUM         // +
	PRODUCT     // *
	PREFIX      // -X ã¾ãŸã¯ !X
	CALL        // myFunction(X)
)

type Parser struct {
	l *lexer.Lexer

	// Lexerã®ã¨ãã¨åŒã˜ä½œæˆ¦ã€‚Lexerã¯ã€Œ1æ–‡å­—ã€å˜ä½ã§ã€Parserã¯ã€Œ1ãƒˆãƒ¼ã‚¯ãƒ³ã€å˜ä½ã§ã™ã­ã€‚
	curToken  token.Token
	peekToken token.Token

	// ãƒ‡ãƒãƒƒã‚°ã‚’æ¥½ã«ã™ã‚‹ãŸã‚ error ã‚’è¨˜éŒ²ã—ã¦ãŠã
	errors []string // stringãŒæ¥½ã§è‰¯ã•ã’

	// ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ—ã”ã¨ã®æ§‹æ–‡è§£æé–¢æ•°ã‚’ã‚‚ã£ã¦ãŠãmap
	prefixFns map[token.TokenType]parsePrefixFn
	infixFns  map[token.TokenType]parseInfixFn
}

func New(l *lexer.Lexer) *Parser {
	p := &Parser{
		l:      l,
		errors: []string{},
	}

	// åˆæœŸåŒ–æ™‚ã«2å›èª­ã¿é€²ã‚ã¦ãŠã
	p.nextToken()
	p.nextToken()

	// å‰ç½®ã®æ§‹æ–‡è§£æé–¢æ•°ã®mapåˆæœŸåŒ–
	p.prefixFns = make(map[token.TokenType]parsePrefixFn)

	p.registerPrefixFn(token.IDENT, p.parseIdentifier)
	p.registerPrefixFn(token.INT, p.parseIntegerLiteral)
	p.registerPrefixFn(token.BANG, p.parsePrefixExpression)
	p.registerPrefixFn(token.MINUS, p.parsePrefixExpression)

	return p
}

func (p *Parser) Errors() []string {
	return p.errors
}

func (p *Parser) peekError(t token.TokenType) {
	msg := fmt.Sprintf("ğŸ‘º æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ %s ã«ãªã£ã¦ã»ã—ã„ã‘ã©ã€ã„ã¾ã‚“ã¨ã“ã‚ %s ã«ãªã£ã¡ã‚ƒã£ã¦ã‚‹ã‚ˆ", t, p.peekToken.Type)
	p.errors = append(p.errors, msg)
}

func (p *Parser) nextToken() {
	p.curToken = p.peekToken
	p.peekToken = p.l.NextToken()
}

func (p *Parser) ParseProgram() *ast.Program {
	program := &ast.Program{}
	program.Statements = []ast.Statement{}

	// ã“ã“ã‚‰ã¸ã‚“ã€æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ã¾ã‚“ã¾ï¼
	for p.curToken.Type != token.EOF {
		stmt := p.parseStatement()

		// æ–‡ãŒæ¥ã‚‹ã¨ã¯é™ã‚‰ãªã„ã‹ã‚‰ã­ã€‚å¼ã ã£ãŸã‚Šã€ILLEGALã ã£ãŸã‚Šã™ã‚‹ã‹ã‚‰ã­
		if stmt != nil {
			program.Statements = append(program.Statements, stmt)
		}

		p.nextToken()
	}

	return program
}

func (p *Parser) parseStatement() ast.Statement {
	// Statement ã® Parse ã® ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ ã£ã¦ã‹ã‚“ã˜ã ã­
	switch p.curToken.Type {
	case token.LET:
		return p.parseLetStatement()
	case token.RETURN:
		return p.parseReturnStatement()
	default:
		return p.parseExpressionStatement()
	}
}

func (p *Parser) expectPeek(t token.TokenType) bool {
	// ãƒãƒ©è¦‹ã—ã¦ã€æœŸå¾…é€šã‚Šãªã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’1ã¤èª­ã¿ã™ã™ã‚ã‚‹ã€‚ãã†ã§ãªã‘ã‚Œã°ã€ä½•ã‚‚ã—ãªã„ã€‚
	// æ§‹æ–‡è§£æå™¨ã®ã‚ˆãã‚ã‚‹å‹•ä½œã‚‰ã—ã„ã­
	if p.peekTokenIs(t) {
		p.nextToken()
		return true
	} else {
		p.peekError(t)
		return false
	}
}

func (p *Parser) curTokenIs(t token.TokenType) bool {
	return p.curToken.Type == t
}

func (p *Parser) peekTokenIs(t token.TokenType) bool {
	return p.peekToken.Type == t
}

func (p *Parser) parseLetStatement() *ast.LetStatement {
	// letæ–‡ ã¨ã„ã† Node ã‚’æ§‹ç¯‰ã—ã¦ã„ãæ„Ÿã˜ã€‚
	stmt := &ast.LetStatement{Token: p.curToken}

	// æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ <identifier> ã§ã‚ã£ã¦ã»ã—ã„ã‹ã‚‰ã­ã€‚
	if !p.expectPeek(token.IDENT) {
		return nil // ã„ã¾ã‚“ã¨ã“ã‚Errorã˜ã‚ƒãªãã¦nilã§
	}

	// <identifier> ã‚’ ç™»éŒ²(ï¼Ÿ)ã™ã‚Œã°ã„ã„
	stmt.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}

	// letæ–‡ãªã‚‰ã€ã¤ãã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ ã€Œ=ã€ ã ã‚ˆã­
	if !p.expectPeek(token.ASSIGN) {
		return nil // ã„ã¾ã‚“ã¨ã“ã‚Errorã˜ã‚ƒãªãã¦nilã§
	}

	// TOã®DO: <expression>ã®ãƒ‘ãƒ¼ã‚¹ã‚’å¾Œå›ã—ã«ã™ã‚‹ã®ã§ã€ã‚»ãƒŸã‚³ãƒ­ãƒ³ãŒãã‚‹ã¾ã§èª­ã¿é£›ã°ã—ã¦ã„ã‚‹ã€‚
	for !p.curTokenIs(token.SEMICOLON) {
		p.nextToken()
	}

	return stmt
}

func (p *Parser) parseReturnStatement() ast.Statement {
	// returnæ–‡ ã¨ã„ã† Node ã‚’æ§‹ç¯‰ã—ã¦ã„ãã
	stmt := &ast.ReturnStatement{Token: p.curToken}

	p.nextToken()

	// TOOD: <expression>ã®ãƒ‘ãƒ¼ã‚¹ã¯å¾Œå›ã—ãªã®ã§ã€ã‚»ãƒŸã‚³ãƒ­ãƒ³ãŒãã‚‹ã§èª­ã¿é£›ã°ã—ã¦ã„ã‚‹
	for !p.curTokenIs(token.SEMICOLON) {
		p.nextToken()
	}

	return stmt
}

type (
	parsePrefixFn func() ast.Expression
	// <left> <op> <right> ã® <left> ãŒå¼•æ•°ãª
	parseInfixFn func(ast.Expression) ast.Expression
)

func (p Parser) registerPrefixFn(tokenType token.TokenType, fn parsePrefixFn) {
	p.prefixFns[tokenType] = fn
}

func (p Parser) registerInfixFn(tokenType token.TokenType, fn parseInfixFn) {
	p.infixFns[tokenType] = fn
}

func (p *Parser) parseExpressionStatement() ast.Statement {
	exprStmt := &ast.ExpressionStatement{Token: p.curToken}

	exprStmt.Expression = p.parseExpression(LOWEST)

	// ãƒˆãƒ¼ã‚¯ãƒ³ã®èª­ã¿é€²ã‚ã‚‚ãŠå¿˜ã‚Œãªã â† æ§‹æ–‡è§£æé–¢æ•°ã§ã¯èª­ã¿é€²ã‚ãªã„ä»•æ§˜ã«ã—ã¦ã„ã‚‹ï¼
	if p.peekTokenIs(token.SEMICOLON) {
		p.nextToken()
	}
	return exprStmt
}

func (p *Parser) parseExpression(precedence int) ast.Expression {
	prefixFn := p.prefixFns[p.curToken.Type]

	if prefixFn == nil {
		p.noPrefixParseFnError(p.curToken.Type)
		return nil
	}

	leftExpr := prefixFn()

	return leftExpr
}

func (p *Parser) parseIdentifier() ast.Expression {
	ident := &ast.Identifier{
		Token: p.curToken,
		Value: p.curToken.Literal,
	}
	return ident
}

func (p *Parser) parseIntegerLiteral() ast.Expression {
	value, err := strconv.ParseInt(p.curToken.Literal, 0, 64)
	if err != nil {
		msg := fmt.Sprintf("colud not parse %q as integer", p.curToken.Literal)
		p.errors = append(p.errors, msg)
		return nil
	}

	intLit := &ast.IntegerLiteral{
		Token: p.curToken,
		Value: value,
	}

	return intLit

}

func (p *Parser) noPrefixParseFnError(t token.TokenType) {
	// é©å¿œã™ã‚‹å‰ç½®ç”¨ã®æ§‹æ–‡è§£æé–¢æ•°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã¨ãã«ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ã‚„ã¤
	msg := fmt.Sprintf("ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ— '%s' ç”¨ã®PrefixParseFnãŒã‚ã‚Šã¾ã›ã‚“ã‚ˆï¼Ÿ", t)
	p.errors = append(p.errors, msg)
}

func (p *Parser) parsePrefixExpression() ast.Expression {
	prefixExpr := &ast.PrefixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
	}
	// ã“ã®é–¢æ•°ãŒå‘¼ã°ã‚Œã¦ã„ã‚‹æ¬¡ç‚¹ã§ã€ token.BANG ã¾ãŸã¯ token.MINUS ãªã®ã§(ãã†æŒ‡å®šã—ãŸã‹ã‚‰)
	// ãã®ã¾ã¾ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª­ã¿é€²ã‚ã‚Œã°ãŠk
	p.nextToken()

	prefixExpr.Right = p.parseExpression(PREFIX)

	return prefixExpr
}
